{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in training and test set\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#Get a first impression of what kind of data is in the train set\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From just looking at the first ten rows, it is apparent that:\n",
    "\n",
    "- PassengerId should be removed\n",
    "- Surived is the outcome variable and needs to be removed before training the model\n",
    "- Pclass, Sex and Embarked need to be encoded as categorical features\n",
    "- Name requires processing to be useful. We can extract whether women were married (by isolating Miss/Mrs) \n",
    "- Ticket number may be irrelevant unless it reflects how or where the ticket was purchased. Will isolate number portion and try\n",
    "- Fare is a numeric predictor and likely important\n",
    "- Not many passengers have a cabin number, so this may not be worth including"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatypes\n",
    "\n",
    "- The numeric features are already the right datatype\n",
    "- Categorical features will need to be replaced with dummy codes using OneHotEncoder (for regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure out datatypes \n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution and count\n",
    "\n",
    "- If I decide to use logistic regression, I'll need to scale the features as they have very different distributions\n",
    "- Looks like there are only 891 data points (and Age has some Nan values) it I should try not replace Nans instead of removing them\n",
    "- Need to check of there are Nans in the non-numeric columns first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN values\n",
    "\n",
    "- Only Age, Cabin and Embarked are missing values.\n",
    "- For age, that means 177/891, that's almost 20% missing! I'll have to plot the distribution to determine what to do here\n",
    "- For Cabin it's 77% NaNs. I will include this as a new categorical feature: whether or not a Cabin is reported\n",
    "- Since Embarked is only missing 2, I will replace these with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age\n",
    "\n",
    "- Looks like there are quite a few very young children. This kind of makes sense as they are less likely to be left at school/with a grandparent etc.\n",
    "- To make sure they are actually children, I will check the name column for these cases below - they seem to all be Miss and Master, so the age info is probably right in these cases\n",
    "- In general, it seems that using the median of age would be a good replacement for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkpr+P6AQ4VxZQRHnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d2fb548048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n, bins, patches = plt.hist(train.Age.dropna(), 20 )\n",
    "plt.title('Age distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "train.Age.median()\n",
    "train.Age.mean()\n",
    "train.Age.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.00</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.00</td>\n",
       "      <td>Laroche, Miss. Simonne Marie Anne Andree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4.00</td>\n",
       "      <td>Skoog, Master. Harald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.83</td>\n",
       "      <td>Caldwell, Master. Alden Gates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Andersson, Miss. Ellis Anna Maria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Panula, Master. Eino Viljami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>4.00</td>\n",
       "      <td>Rice, Master. Arthur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Johnson, Miss. Eleanor Ileen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Becker, Master. Richard F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4.00</td>\n",
       "      <td>Kink-Heilmann, Miss. Luise Gretchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3.00</td>\n",
       "      <td>Navratil, Master. Michel M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Strom, Miss. Telma Matilda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>3.00</td>\n",
       "      <td>Asplund, Master. Edvin Rojj Felix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.92</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Navratil, Master. Edmond Roger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3.00</td>\n",
       "      <td>Coutts, Master. William Loch \"William\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>3.00</td>\n",
       "      <td>Palsson, Miss. Stina Viola</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age                                      Name\n",
       "7    2.00            Palsson, Master. Gosta Leonard\n",
       "10   4.00           Sandstrom, Miss. Marguerite Rut\n",
       "16   2.00                      Rice, Master. Eugene\n",
       "43   3.00  Laroche, Miss. Simonne Marie Anne Andree\n",
       "63   4.00                     Skoog, Master. Harald\n",
       "78   0.83             Caldwell, Master. Alden Gates\n",
       "119  2.00         Andersson, Miss. Ellis Anna Maria\n",
       "164  1.00              Panula, Master. Eino Viljami\n",
       "171  4.00                      Rice, Master. Arthur\n",
       "172  1.00              Johnson, Miss. Eleanor Ileen\n",
       "183  1.00                 Becker, Master. Richard F\n",
       "184  4.00       Kink-Heilmann, Miss. Luise Gretchen\n",
       "193  3.00                Navratil, Master. Michel M\n",
       "205  2.00                Strom, Miss. Telma Matilda\n",
       "261  3.00         Asplund, Master. Edvin Rojj Felix\n",
       "297  2.00              Allison, Miss. Helen Loraine\n",
       "305  0.92            Allison, Master. Hudson Trevor\n",
       "340  2.00            Navratil, Master. Edmond Roger\n",
       "348  3.00    Coutts, Master. William Loch \"William\"\n",
       "374  3.00                Palsson, Miss. Stina Viola"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Age < 5][['Age','Name']].head(20)\n",
    "# The girls seems to all be Miss and the boys Master (cute!) so it seems this not a mistake. Let's leave it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a copy of train and test datasets to work with and remove PassengerId and Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train.copy()\n",
    "test_copy = test.copy()\n",
    "\n",
    "del train_copy['PassengerId']\n",
    "#passengerid = test_copy['PassengerId'].copy()\n",
    "#train_copy = train_copy.drop(['PassengerId'], axis = 1)\n",
    "\n",
    "del train_copy['Ticket']\n",
    "del test_copy['Ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features\n",
    "\n",
    "Next I need to convert Pclass, Sex and Embarked into categorical features. I won't dummy-code them just yet as it is not necessary for Tree-based models (which I'll try first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert PClass to categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_copy.Pclass = train_copy.Pclass.astype('category')\n",
    "test_copy.Pclass = test_copy.Pclass.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace null values in Age with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.Age = train_copy.Age.fillna(train.Age.median())\n",
    "test_copy.Age = test_copy.Age.fillna(train.Age.median())\n",
    "\n",
    "# Confirm that there are no more null values in Age\n",
    "train_copy.Age.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace null values in Fare with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.Fare = train_copy.Fare.fillna(train.Fare.median())\n",
    "test_copy.Fare = test_copy.Fare.fillna(train.Fare.median())\n",
    "\n",
    "# Confirm that there are no more null values in Age\n",
    "train_copy.Fare.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace null values in Embarked with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode\n",
    "embarkmode = train_copy['Embarked'].mode()\n",
    "\n",
    "# Replace null values with mode (both in train and test) \n",
    "train_copy.loc[(train_copy['Embarked'].isnull()), 'Embarked'] = embarkmode.values[0]\n",
    "test_copy.loc[(test_copy['Embarked'].isnull()), 'Embarked'] = embarkmode.values[0]\n",
    "\n",
    "# Confirm that there are no more null values in Embarked\n",
    "train_copy.Embarked.isnull().sum()\n",
    "\n",
    "# Convert to categorical data type\n",
    "train_copy.Embarked = train_copy.Embarked.astype('category')\n",
    "test_copy.Embarked = test_copy.Embarked.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Cabin feature to 1 for 'has cabin info' vs. 0 for 'has no cabin info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "regex_pat = re.compile(r'[1-9A-Za-z 0]*') # If Cabin contains any characters at all\n",
    "train_copy.Cabin = train_copy.Cabin.str.replace(regex_pat, '1') # Replace these with a 1 (string to conform with data type)\n",
    "test_copy.Cabin = test_copy.Cabin.str.replace(regex_pat, '1') # Do the same for the test set\n",
    "\n",
    "train_copy.Cabin = train_copy.Cabin.fillna(0) # Replace NaN values in Cabin with 0\n",
    "test_copy.Cabin = test_copy.Cabin.fillna(0) # Same again for the test set\n",
    "\n",
    "# Now make it a categorical feature\n",
    "train_copy.Cabin = train_copy.Cabin.astype('category')\n",
    "test_copy.Cabin = test_copy.Cabin.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Sex and Embarked into numeric categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    category\n",
       "Pclass      category\n",
       "Name          object\n",
       "Sex         category\n",
       "Age          float64\n",
       "SibSp          int64\n",
       "Parch          int64\n",
       "Fare         float64\n",
       "Cabin       category\n",
       "Embarked    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that replaces categorical variables with integers\n",
    "def replace_with_int(df, column, vals, replacevals):\n",
    "    for i in range(len(vals)):\n",
    "        df[column] = df[column].replace(vals[i], replacevals[i])\n",
    "    return df\n",
    "\n",
    "train_copy = replace_with_int(train_copy, 'Sex', ['male','female'], [0, 1])\n",
    "test_copy = replace_with_int(test_copy, 'Sex', ['male','female'], [0, 1])\n",
    "\n",
    "train_copy = replace_with_int(train_copy, 'Embarked', ['S', 'C', 'Q'], [0, 1, 2])\n",
    "test_copy = replace_with_int(test_copy, 'Embarked', ['S', 'C', 'Q'], [0, 1, 2])\n",
    "\n",
    "# Convert categorical variables to category datatype\n",
    "for col in ['Pclass', 'Sex', 'Cabin', 'Embarked']:\n",
    "    train_copy[col] = train_copy[col].astype('category')\n",
    "    test_copy[col] = test_copy[col].astype('category')\n",
    "    \n",
    "train_copy['Survived'] = train_copy['Survived'].astype('category')\n",
    "\n",
    "train_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the names\n",
    "\n",
    "- Try and isolate Miss and Mrs from the name feature as this will give us information about female marital status\n",
    "- Also, by combining it with the Parents/children feature we can make a good estimate of whether they are mothers/fathers\n",
    "- While those under 18 who have Parents/children are likely to be accompanied by parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First isolate the title using regex\n",
    "regex_pat = re.compile('(.*, )|(\\\\..*)')\n",
    "train_copy['Title'] = train_copy.Name.str.replace(regex_pat, '')\n",
    "test_copy['Title'] = test_copy.Name.str.replace(regex_pat, '')\n",
    "\n",
    "# If they are => 18 and Parent/Child column >0 then they are likely to be parents\n",
    "are_parents_index = train_copy.loc[(train_copy['Age'] >= 18) & (train_copy['Parch'] > 0)].index\n",
    "train_copy['WithChild'] = 0\n",
    "train_copy.loc[are_parents_index,'WithChild'] = 1\n",
    "are_parents_index = test_copy.loc[(test_copy['Age'] >= 18) & (test_copy['Parch'] > 0)].index\n",
    "test_copy['WithChild'] = 0\n",
    "test_copy.loc[are_parents_index,'WithChild'] = 1\n",
    "\n",
    "# Kids that had at least one parent on board\n",
    "with_parents_index = train_copy.loc[(train_copy['Age'] < 18) & (train_copy['Parch'] >= 1)].index\n",
    "train_copy['NumOfParents'] = 0\n",
    "train_copy.loc[with_parents_index, 'NumOfParents'] = 1\n",
    "with_parents_index = test_copy.loc[(test_copy['Age'] < 18) & (test_copy['Parch'] >= 1)].index\n",
    "test_copy['NumOfParents'] = 0\n",
    "test_copy.loc[with_parents_index, 'NumOfParents'] = 1\n",
    "\n",
    "# If they are >= 18 and have only one Sibling/Spouse on board, they are probably accompanied by their Wife/Husband\n",
    "with_spouse_index = train_copy.loc[(train_copy['Age'] >= 18) & (train_copy['SibSp'] == 1)].index\n",
    "train_copy['WithSpouse'] = 0\n",
    "train_copy.loc[with_spouse_index, 'WithSpouse'] = 1\n",
    "with_spouse_index = test_copy.loc[(test_copy['Age'] >= 18) & (test_copy['SibSp'] == 1)].index\n",
    "test_copy['WithSpouse'] = 0\n",
    "test_copy.loc[with_spouse_index, 'WithSpouse'] = 1\n",
    "\n",
    "# It seems there are a small number of high-ranking individuals (based on their title)\n",
    "train_copy['Title'].value_counts()\n",
    "\n",
    "# Let's lump special titles together since they might not all occur in the test set, 5 seems to be a good cutoff point (doctors might be a good separate group)\n",
    "special_titles = train_copy['Title'].value_counts()\n",
    "special_title_list = list(special_titles[special_titles <= 10].index)\n",
    "train_copy['Title'].replace(special_title_list, 'Special', inplace = True)\n",
    "special_titles = test_copy['Title'].value_counts()\n",
    "special_title_list = list(special_titles[special_titles <= 10].index)\n",
    "test_copy['Title'].replace(special_title_list, 'Special', inplace = True)\n",
    "\n",
    "# Convert these to numerical values so they can be used as a categorical feature\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_copy['TitleCode'] = le.fit_transform(train_copy['Title'])\n",
    "test_copy['TitleCode'] = le.fit_transform(test_copy['Title'])\n",
    "\n",
    "for col in ['TitleCode', 'WithSpouse', 'NumOfParents', 'WithChild']:\n",
    "    train_copy[col] = train_copy[col].astype('category')\n",
    "    test_copy[col] = test_copy[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now remove Name and Title from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_copy['Name']\n",
    "del train_copy['Title']\n",
    "del test_copy['Name']\n",
    "del test_copy['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        category\n",
       "Pclass          category\n",
       "Sex             category\n",
       "Age              float64\n",
       "SibSp              int64\n",
       "Parch              int64\n",
       "Fare             float64\n",
       "Cabin           category\n",
       "Embarked        category\n",
       "WithChild       category\n",
       "NumOfParents    category\n",
       "WithSpouse      category\n",
       "TitleCode       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prepare model for Random Forest Classification\n",
    "\n",
    "- Split train set into train/validation sets\n",
    "- Train model\n",
    "- Get accuracy score on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X and y\n",
    "y = train_copy['Survived'].copy()\n",
    "X = train_copy.drop(['Survived'], axis = 1)\n",
    "\n",
    "# train/test(/validation) split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08513807  0.16063571  0.22800637  0.02261798  0.02633666  0.22943639\n",
      "  0.04559541  0.04218279  0.01178071  0.00650663  0.01463475  0.12712853]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get accuracy score on training set\n",
    "\n",
    "- Looks like the model has a fit of 97% on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97005988023952094"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get accuracy score on test/validation set\n",
    "\n",
    "- For the test set, the accuracy score is almost 79%, which is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7982062780269058"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 5-fold validation, I get an average score of 77% on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77027755957056809"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42, n_estimators = 100)\n",
    "clf.fit(X, y)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv = 5, scoring='precision')\n",
    "\n",
    "import numpy as np\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get test-predictions for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passengerid = test_copy['PassengerId'].copy()\n",
    "#test_copy = test_copy.drop(['PassengerId'], axis = 1)\n",
    "#passengerid\n",
    "y_pred = clf.predict(test_copy)\n",
    "passengerid\n",
    "y_survived = pd.DataFrame(data = y_pred, columns = ['Survived'])\n",
    "pd.concat([passengerid,y_survived], axis = 1).set_index('PassengerId').to_csv('submission.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
